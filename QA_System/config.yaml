# config/config.yaml
system:
  log_level: "INFO"  # DEBUG/INFO/WARNING/ERROR
  device: "cuda"  # cuda/cpu
  seed: 42

data:
  input_file: "./data/original_data/"
  model_output_dir: "./model/pkl/"
  data_output_dir: "./data/processed_data/" # save the processed data, which used for training and generating
  val_path: "./data/original_data/val.jsonl" # validation data path
  test_path: "./data/original_data/test.jsonl" # test data path

paths:
  data_root: "./data/data"
  model_root: "./models/"
  cache_dir: "./cache/"
  log_dir: "./logs/"

modules:
  active:  
    retrieval: "hybrid"  # bm25/bert_base/hybrid to choose the retrieval method
    generator: "qwen"
    evaluator: "eval.metrics_calculation"
    ui: "webui"
    process: "process.process"

# 检索模型配置（用于WebUI和所有检索服务）
retrieval:
  # 检索公共选项
  top_k: 5  # 默认返回的文档数量
  use_plain_text: true  # 是否使用纯文本而非markdown
  max_words: 10  # 提取答案的最大单词数
  
  # 文本检索模型配置
  text_retrieval:
    method: "hybrid"  # bm25/tfidf/hybrid
    hybrid_alpha: 0.7  # hybrid模式下BM25的权重 (0.3tfidf+0.7bm25)
    
  # 深度嵌入检索模型配置
  deep_retrieval:
    # BGE-M3配置
    bgem3:
      model: "BAAI/bge-m3"
      api_key: "sk-???"
      result_path: "./data/result/val_query_vectors.jsonl"
      faiss_path: "./cache/faiss/bgem3.faiss"
      chunk_size: 10  # 每批处理的文档数量
      overlap_ratio: 0.2  # 文本分割重叠率(0-0.5)
      use_weighted_avg: true  # 使用加权平均而非简单平均
      auto_load: true  # 自动加载中间结果
    # 本地BERT配置
    local_embedding:
      model: "nomic-ai/nomic-bert-2048"
      doc_path: "./data/processed_data/processed_plain.jsonl"
      chunk_size: 10
      overlap_ratio: 0.2
      auto_load: true
    
  # 混合检索模型配置
  hybrid:
    weights: 
      bm25: 0.4
      dpr: 0.6
    fusion_method: "weighted_sum"  # reciprocal_rank/round_robin

  # FAISS配置
  faiss:
    index_path: "./faiss/"  # FAISS索引存储路径

# BERT-Base训练配置
bert_base:
  train:
    model_name_or_path: "nomic-ai/nomic-bert-2048"  # 支持长序列的预训练模型
    shared_weights: false  # 是否共享查询和文档编码器的权重
    temperature: 0.05  # 相似度计算的温度系数
    num_train_epochs: 5  # 训练轮数
    batch_size: 2  # 训练批次大小s
    learning_rate: 3.0e-5  # 学习率
    weight_decay: 0.01  # 权重衰减
    max_query_length: 128  # 查询文本的最大长度
    max_ctx_length: 2048  # 上下文文本的最大长度（利用长序列能力）
    warmup_steps: 0  # 学习率预热步数
    adam_epsilon: 1.0e-8  # Adam优化器的epsilon值
    eval_steps: 0  # 每多少步评估一次,0为不评估
    gradient_accumulation_steps: 2  # 梯度累积步数
    num_workers: 4  # 数据加载器的工作进程数

# 文本生成配置
generation:
  qwen:
    api_key: "sk-nfizfypjawwnixaimezwbkxbhomzpuozlungqykzkwyporuk"

rerank:
  api_key: "sk-nfizfypjawwnixaimezwbkxbhomzpuozlungqykzkwyporuk"
  url: "https://api.siliconflower.com/v1/rerank"

# WebUI配置
webui:
  port: 8080
  presentation: true  # true to open webui / false only for debug

# 评估配置
evaluation:
  # 评估模式的通用配置
  default_method: "text"  # 默认评估方法: text/deep_embedding/hybrid
  auto_select: false  # 是否自动选择默认方法(true)，还是提示用户选择(false)
  
  # 评估指标配置
  metrics:
    calculate: true  # 是否计算评估指标
    types: ["recall", "mrr"]  # 要计算的指标类型
  # 评估输出路径配置
  output:
    text: "./data/evaluation/text_evaluation_results.jsonl"
    deep_embedding: "./data/evaluation/deep_embedding_evaluation_results.jsonl"
    hybrid: "./data/evaluation/hybrid_evaluation_results.jsonl"

# 调试模式配置
debug:
  train_mode: false # 启用训练模式 (训练bert_base模型)
  evaluate_mode: false  # 启用评估模式 (执行评估流程)
  process_mode: false # 启用处理模式 (执行数据处理流程)
  vectorize_mode: false # 启用向量化模式 (执行文档向量化并创建FAISS索引)
  rerank_mode: false # 启用重排序模式 (执行重排序流程)
